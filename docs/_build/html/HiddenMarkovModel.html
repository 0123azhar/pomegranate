

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Hidden Markov Models &mdash; pomegranate 0.6.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="pomegranate 0.6.0 documentation" href="index.html"/>
        <link rel="next" title="Naive Bayes Classifiers" href="NaiveBayes.html"/>
        <link rel="prev" title="General Mixture Models" href="GeneralMixtureModel.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> pomegranate
          

          
          </a>

          
            
            
              <div class="version">
                0.6.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="ooc.html">Out of Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="Distributions.html">Probability Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="GeneralMixtureModel.html">General Mixture Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Hidden Markov Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#initialization">Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#log-probability">Log Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="#prediction">Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fitting">Fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-pomegranate.hmm">API Reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="NaiveBayes.html">Naive Bayes Classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="MarkovChain.html">Markov Chains</a></li>
<li class="toctree-l1"><a class="reference internal" href="BayesianNetwork.html">Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="FactorGraph.html">Factor Graphs</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">pomegranate</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Hidden Markov Models</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/HiddenMarkovModel.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="hidden-markov-models">
<span id="hiddenmarkovmodel"></span><h1>Hidden Markov Models<a class="headerlink" href="#hidden-markov-models" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><a class="reference external" href="https://github.com/jmschrei/pomegranate/blob/master/tutorials/Tutorial_3_Hidden_Markov_Models.ipynb">IPython Notebook Tutorial</a></li>
<li><a class="reference external" href="http://nbviewer.ipython.org/github/jmschrei/yahmm/blob/master/examples/Global%20Sequence%20Alignment.ipynb">IPython Notebook Sequence Alignment Tutorial</a></li>
</ul>
<p><a class="reference external" href="http://en.wikipedia.org/wiki/Hidden_Markov_model">Hidden Markov models</a> (HMMs) are a form of structured model in which a sequence of observations are labelled according to the hidden state they belong. A strength of HMMs is their ability to analyze variable length sequences whereas other models require a static set of features. This makes them extensively used in the fields of natural language processing and bioinformatics where data is routinely variable length sequences. They can be thought of as a structured form of General Mixture Models.</p>
<div class="section" id="initialization">
<h2>Initialization<a class="headerlink" href="#initialization" title="Permalink to this headline">¶</a></h2>
<p>Transitioning from YAHMM to pomegranate is simple because the only change is that the <code class="docutils literal"><span class="pre">Model</span></code> class is now <code class="docutils literal"><span class="pre">HiddenMarkovModel</span></code>. You can port your code over by either changing <code class="docutils literal"><span class="pre">Model</span></code> to <code class="docutils literal"><span class="pre">HiddenMarkovModel</span></code> or changing your imports at the top of the file as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pomegranate</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pomegranate</span> <span class="kn">import</span> <span class="n">HiddenMarkovModel</span> <span class="k">as</span> <span class="n">Model</span>
</pre></div>
</div>
<p>instead of</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">yahmm</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
<p>Since hidden Markov models are graphical structures, that structure has to be defined. pomegranate allows you to define this structure either through matrices as is common in other packages, or build it up state by state and edge by edge. pomegranate differs from other packages in that it offers both explicit start and end states which you must begin in or end in. Explicit end states give you more control over the model because algorithms require ending there, as opposed to in any state in the model. It also offers silent states, which are states without explicit emission distributions but can be used to significantly simplify the graphical structure.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pomegranate</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dists</span> <span class="o">=</span> <span class="p">[</span><span class="n">NormalDistribution</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">NormalDistribution</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">NormalDistribution</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">2</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trans_mat</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="go">                             [0.0, 0.8, 0.2],</span>
<span class="go">                             [0.0, 0.0, 0.9]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">starts</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ends</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">HiddenMarkovModel</span><span class="o">.</span><span class="n">from_matrix</span><span class="p">(</span><span class="n">trans_mat</span><span class="p">,</span> <span class="n">dists</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">ends</span><span class="p">)</span>
</pre></div>
</div>
<p>Alternatively this model could be created edge by edge and state by state. This is helpful for large sparse graphs. You must add transitions using the explicit start and end states where the sum of probabilities leaving a state sums to 1.0.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pomegranate</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s1</span> <span class="o">=</span> <span class="n">State</span><span class="p">(</span> <span class="n">Distribution</span><span class="p">(</span> <span class="n">NormalDistribution</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">)</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s2</span> <span class="o">=</span> <span class="n">State</span><span class="p">(</span> <span class="n">Distribution</span><span class="p">(</span> <span class="n">NormalDistribution</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span> <span class="p">)</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s3</span> <span class="o">=</span> <span class="n">State</span><span class="p">(</span> <span class="n">Distribution</span><span class="p">(</span> <span class="n">NormalDistribution</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="p">)</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">HiddenMarkovModel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_states</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span><span class="n">s2</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span><span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span><span class="n">s3</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span><span class="n">s3</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">end</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">bake</span><span class="p">()</span>
</pre></div>
</div>
<p>Models built in this manner must be explicitly &#8220;baked&#8221; at the end. This finalizes the model topology and creates the internal sparse matrix which makes up the model. This removes &#8220;orphan&#8221; parts of the model, normalizes all transitions to make sure they sum to 1.0, stores information about tied distributions, edges, and pseudocounts, and merges unneccesary silent states in the model for computational efficiency. This can cause the <cite>bake</cite> step to take a little bit of time. If you want to reduce this overhead and are sure you specified the model correctly you can pass in <cite>merge=&#8221;None&#8221;</cite> to the bake step to avoid model checking.</p>
</div>
<div class="section" id="log-probability">
<h2>Log Probability<a class="headerlink" href="#log-probability" title="Permalink to this headline">¶</a></h2>
<p>There are two common forms of the log probability which are used. The first is the log probability of the most likely path the sequence can take through the model, called the Viterbi probability. This can be calculated using <code class="docutils literal"><span class="pre">model.viterbi(sequence)</span></code>.  However, this is <span class="math">\(P(D|S_{ML}, S_{ML}, S_{ML})\)</span> not <span class="math">\(P(D|M)\)</span>. In order to get <span class="math">\(P(D|M)\)</span> we have to sum over all possible paths instead of just the single most likely path, which can be calculated using <code class="docutils literal"><span class="pre">model.log_probability(sequence)</span></code> using the forward or backward algorithms. On that note, the full forward matrix can be returned using <code class="docutils literal"><span class="pre">model.forward(sequence)</span></code> and the full backward matrix can be returned using <code class="docutils literal"><span class="pre">model.backward(sequence)</span></code>.</p>
</div>
<div class="section" id="prediction">
<h2>Prediction<a class="headerlink" href="#prediction" title="Permalink to this headline">¶</a></h2>
<p>A common prediction technique is calculating the Viterbi path, which is the most likely sequence of states that generated the sequence given the full model. This is solved using a simple dynamic programming algorithm similar to sequence alignment in bioinformatics. This can be called using <code class="docutils literal"><span class="pre">model.viterbi(sequence)</span></code>. A sklearn wrapper can be called using <code class="docutils literal"><span class="pre">model.predict(sequence,</span> <span class="pre">algorithm='viterbi')</span></code>.</p>
<p>Another prediction technique is called maximum a posteriori or forward-backward, which uses the forward and backward algorithms to calculate the most likely state per observation in the sequence given the entire remaining alignment. Much like the forward algorithm can calculate the sum-of-all-paths probability instead of the most likely single path, the forward-backward algorithm calculates the best sum-of-all-paths state assignment instead of calculating the single best path. This can be called using <code class="docutils literal"><span class="pre">model.predict(sequence,</span> <span class="pre">algorithm='map')</span></code> and the raw normalized probability matrices can be called using <code class="docutils literal"><span class="pre">model.predict_proba(sequence)</span></code>.</p>
</div>
<div class="section" id="fitting">
<h2>Fitting<a class="headerlink" href="#fitting" title="Permalink to this headline">¶</a></h2>
<p>A simple fitting algorithm for hidden Markov models is called Viterbi training. In this method, each observation is tagged with the most likely state to generate it using the Viterbi algorithm. The distributions (emissions) of each states are then updated using MLE estimates on the observations which were generated from them, and the transition matrix is updated by looking at pairs of adjacent state taggings. This can be done using <code class="docutils literal"><span class="pre">model.fit(sequence,</span> <span class="pre">algorithm='viterbi')</span></code>.</p>
<p>However, this is not the best way to do training and much like the other sections there is a way of doing training using sum-of-all-paths probabilities instead of maximally likely path. This is called Baum-Welch or forward-backward training. Instead of using hard assignments based on the Viterbi path, observations are given weights equal to the probability of them having been generated by that state. Weighted MLE can then be done to updates the distributions, and the soft transition matrix can give a more precise probability estimate. This is the default training algorithm, and can be called using either <code class="docutils literal"><span class="pre">model.fit(sequences)</span></code> or explicitly using <code class="docutils literal"><span class="pre">model.fit(sequences,</span> <span class="pre">algorithm='baum-welch')</span></code>.</p>
<p>Fitting in pomegranate also has a number of options, including the use of distribution or edge inertia, freezing certain states, tying distributions or edges, and using pseudocounts. See the tutorial linked to at the top of this page for full details on each of these options.</p>
</div>
<div class="section" id="module-pomegranate.hmm">
<span id="api-reference"></span><h2>API Reference<a class="headerlink" href="#module-pomegranate.hmm" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pomegranate.hmm.HiddenMarkovModel">
<em class="property">class </em><code class="descclassname">pomegranate.hmm.</code><code class="descname">HiddenMarkovModel</code><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel" title="Permalink to this definition">¶</a></dt>
<dd><p>A Hidden Markov Model</p>
<p>A Hidden Markov Model (HMM) is a directed graphical model where nodes are
hidden states which contain an observed emission distribution and edges
contain the probability of transitioning from one hidden state to another.
HMMs allow you to tag each observation in a variable length sequence with
the most likely hidden state according to the model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>name</strong> : str, optional</p>
<blockquote>
<div><p>The name of the model. Default is None.</p>
</div></blockquote>
<p><strong>start</strong> : State, optional</p>
<blockquote>
<div><p>An optional state to force the model to start in. Default is None.</p>
</div></blockquote>
<p><strong>end</strong> : State, optional</p>
<blockquote class="last">
<div><p>An optional state to force the model to end in. Default is None.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pomegranate</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d1</span> <span class="o">=</span> <span class="n">DiscreteDistribution</span><span class="p">({</span><span class="s1">&#39;A&#39;</span> <span class="p">:</span> <span class="mf">0.35</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span> <span class="p">:</span> <span class="mf">0.20</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span> <span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span> <span class="p">:</span> <span class="mi">40</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2</span> <span class="o">=</span> <span class="n">DiscreteDistribution</span><span class="p">({</span><span class="s1">&#39;A&#39;</span> <span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span> <span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span> <span class="p">:</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span> <span class="p">:</span> <span class="mi">25</span><span class="p">})</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d3</span> <span class="o">=</span> <span class="n">DiscreteDistribution</span><span class="p">({</span><span class="s1">&#39;A&#39;</span> <span class="p">:</span> <span class="mf">0.10</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span> <span class="p">:</span> <span class="mf">0.40</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span> <span class="p">:</span> <span class="mf">0.40</span><span class="p">,</span> <span class="s1">&#39;T&#39;</span> <span class="p">:</span> <span class="mi">10</span><span class="p">})</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s1</span> <span class="o">=</span> <span class="n">State</span><span class="p">(</span> <span class="n">d1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;s1&quot;</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s2</span> <span class="o">=</span> <span class="n">State</span><span class="p">(</span> <span class="n">d2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;s2&quot;</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s3</span> <span class="o">=</span> <span class="n">State</span><span class="p">(</span> <span class="n">d3</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;s3&quot;</span> <span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">HiddenMarkovModel</span><span class="p">(</span><span class="s1">&#39;example&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_states</span><span class="p">([</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span> <span class="n">model</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="mf">0.90</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span> <span class="n">model</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="mf">0.10</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="mf">0.80</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="mf">0.20</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span> <span class="n">s2</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="mf">0.90</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span> <span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="mf">0.10</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span> <span class="n">s3</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="mf">0.70</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transition</span><span class="p">(</span> <span class="n">s3</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">end</span><span class="p">,</span> <span class="mf">0.30</span> <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">bake</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">log_probability</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ACGACTATTCGAT&#39;</span><span class="p">))</span>
<span class="go">-4.31828085576</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span> <span class="n">state</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">viterbi</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ACGACTATTCGAT&#39;</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
<span class="go">example-start, s1, s2, s2, s2, s2, s2, s2, s2, s2, s2, s2, s2, s3, example-end</span>
</pre></div>
</div>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="14%" />
<col width="86%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>start</td>
<td>(State) A state object corresponding to the initial start of the model</td>
</tr>
<tr class="row-even"><td>end</td>
<td>(State) A state object corresponding to the forced end of the model</td>
</tr>
<tr class="row-odd"><td>start_index</td>
<td>(int) The index of the start object in the state list</td>
</tr>
<tr class="row-even"><td>end_index</td>
<td>(int) The index of the end object in the state list</td>
</tr>
<tr class="row-odd"><td>silent_start</td>
<td>(int) The index of the beginning of the silent states in the state list</td>
</tr>
<tr class="row-even"><td>states</td>
<td>(list) The list of all states in the model, with silent states at the end</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.add_edge">
<code class="descname">add_edge</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.add_edge" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a transition from state a to state b which indicates that B is
dependent on A in ways specified by the distribution.</p>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.add_model">
<code class="descname">add_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.add_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Add the states and edges of another model to this model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>other</strong> : HiddenMarkovModel</p>
<blockquote>
<div><p>The other model to add</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.add_node">
<code class="descname">add_node</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.add_node" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a node to the graph.</p>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.add_nodes">
<code class="descname">add_nodes</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.add_nodes" title="Permalink to this definition">¶</a></dt>
<dd><p>Add multiple states to the graph.</p>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.add_state">
<code class="descname">add_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.add_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a state to the given model.</p>
<p>The state must not already be in the model, nor may it be part of any
other model that will eventually be combined with this one.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>state</strong> : State</p>
<blockquote>
<div><p>A state object to be added to the model.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.add_states">
<code class="descname">add_states</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.add_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Add multiple states to the model at the same time.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>states</strong> : list or generator</p>
<blockquote>
<div><p>Either a list of states which are entered sequentially, or just
comma separated values, for example model.add_states(a, b, c, d).</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.add_transition">
<code class="descname">add_transition</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.add_transition" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a transition from state a to state b.</p>
<p>Add a transition from state a to state b with the given (non-log)
probability. Both states must be in the HMM already. self.start and
self.end are valid arguments here. Probabilities will be normalized
such that every node has edges summing to 1. leaving that node, but
only when the model is baked. Psueodocounts are allowed as a way of
using edge-specific pseudocounts for training.</p>
<p>By specifying a group as a string, you can tie edges together by giving
them the same group. This means that a transition across one edge in the
group counts as a transition across all edges in terms of training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>a</strong> : State</p>
<blockquote>
<div><p>The state that the edge originates from</p>
</div></blockquote>
<p><strong>b</strong> : State</p>
<blockquote>
<div><p>The state that the edge goes to</p>
</div></blockquote>
<p><strong>probability</strong> : double</p>
<blockquote>
<div><p>The probability of transitioning from state a to state b in [0, 1]</p>
</div></blockquote>
<p><strong>pseudocount</strong> : double, optional</p>
<blockquote>
<div><p>The pseudocount to use for this specific edge if using edge
pseudocounts for training. Defaults to the probability. Default
is None.</p>
</div></blockquote>
<p><strong>group</strong> : str, optional</p>
<blockquote>
<div><p>The name of the group of edges to tie together during training. If
groups are used, then a transition across any one edge counts as a
transition across all edges. Default is None.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.add_transitions">
<code class="descname">add_transitions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.add_transitions" title="Permalink to this definition">¶</a></dt>
<dd><p>Add many transitions at the same time,</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>a</strong> : State or list</p>
<blockquote>
<div><p>Either a state or a list of states where the edges originate.</p>
</div></blockquote>
<p><strong>b</strong> : State or list</p>
<blockquote>
<div><p>Either a state or a list of states where the edges go to.</p>
</div></blockquote>
<p><strong>probabilities</strong> : list</p>
<blockquote>
<div><p>The probabilities associated with each transition.</p>
</div></blockquote>
<p><strong>pseudocounts</strong> : list, optional</p>
<blockquote>
<div><p>The pseudocounts associated with each transition. Default is None.</p>
</div></blockquote>
<p><strong>groups</strong> : list, optional</p>
<blockquote>
<div><p>The groups of each edge. Default is None.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transitions</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">s1</span><span class="p">],</span> <span class="p">[</span><span class="n">s1</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">end</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transitions</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">],</span> <span class="n">s4</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">add_transitions</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="p">[</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.backward">
<code class="descname">backward</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the backward algorithm on the sequence.</p>
<p>Calculate the probability of each observation being aligned to each
state by going backward through a sequence. Returns the full backward
matrix. Each index i, j corresponds to the sum-of-all-paths log
probability of starting at the end of the sequence, and aligning
observations to hidden states in such a manner that observation i was
aligned to hidden state j. Uses row normalization to dynamically scale
each row to prevent underflow errors.</p>
<p>If the sequence is impossible, will return a matrix of nans.</p>
<dl class="docutils">
<dt>See also:</dt>
<dd><ul class="first last simple">
<li>Silent state handling taken from p. 71 of &#8220;Biological</li>
</ul>
</dd>
</dl>
<p>Sequence Analysis&#8221; by Durbin et al., and works for anything which
does not have loops of silent states.</p>
<blockquote>
<div><ul class="simple">
<li>Row normalization technique explained by</li>
</ul>
</div></blockquote>
<p><a class="reference external" href="http://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf">http://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf</a> on p. 14.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>An array (or list) of observations.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>matrix</strong> : array-like, shape (len(sequence), n_states)</p>
<blockquote class="last">
<div><p>The probability of aligning the sequences to states in a backward
fashion.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.bake">
<code class="descname">bake</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.bake" title="Permalink to this definition">¶</a></dt>
<dd><p>Finalize the topology of the model.</p>
<p>Finalize the topology of the model and assign a numerical index to
every state. This method must be called before any of the probability-
calculating methods.</p>
<p>This fills in self.states (a list of all states in order) and
self.transition_log_probabilities (log probabilities for transitions),
as well as self.start_index and self.end_index, and self.silent_start
(the index of the first silent state).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>verbose</strong> : bool, optional</p>
<blockquote>
<div><p>Return a log of changes made to the model during normalization
or merging. Default is False.</p>
</div></blockquote>
<p><strong>merge</strong> : &#8220;None&#8221;, &#8220;Partial, &#8220;All&#8221;</p>
<blockquote>
<div><p>Merging has three options:
&#8220;None&#8221;: No modifications will be made to the model.
&#8220;Partial&#8221;: A silent state which only has a probability 1 transition</p>
<blockquote>
<div><p>to another silent state will be merged with that silent state.
This means that if silent state &#8220;S1&#8221; has a single transition
to silent state &#8220;S2&#8221;, that all transitions to S1 will now go
to S2, with the same probability as before, and S1 will be
removed from the model.</p>
</div></blockquote>
<dl class="docutils">
<dt>&#8220;All&#8221;: A silent state with a probability 1 transition to any other</dt>
<dd><p class="first last">state, silent or symbol emitting, will be merged in the manner
described above. In addition, any orphan states will be removed
from the model. An orphan state is a state which does not have
any transitions to it OR does not have any transitions from it,
except for the start and end of the model. This will iteratively
remove orphan chains from the model. This is sometimes desirable,
as all states should have both a transition in to get to that
state, and a transition out, even if it is only to itself. If
the state does not have either, the HMM will likely not work as
intended.</p>
</dd>
</dl>
<p>Default is &#8216;All&#8217;.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.clear_summaries">
<code class="descname">clear_summaries</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.clear_summaries" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear the summary statistics stored in the object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>None</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.concatenate">
<code class="descname">concatenate</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.concatenate" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenate this model to another model.</p>
<p>Concatenate this model to another model in such a way that a single
probability 1 edge is added between self.end and other.start. Rename
all other states appropriately by adding a suffix or prefix if needed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>other</strong> : HiddenMarkovModel</p>
<blockquote>
<div><p>The other model to concatenate</p>
</div></blockquote>
<p><strong>suffix</strong> : str, optional</p>
<blockquote>
<div><p>Add the suffix to the end of all state names in the other model.
Default is &#8216;&#8217;.</p>
</div></blockquote>
<p><strong>prefix</strong> : str, optional</p>
<blockquote>
<div><p>Add the prefix to the beginning of all state names in the other
model. Default is &#8216;&#8217;.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a deep copy of the HMM.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>None</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>model</strong> : HiddenMarkovModel</p>
<blockquote class="last">
<div><p>A deep copy of the model with entirely new objects.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.dense_transition_matrix">
<code class="descname">dense_transition_matrix</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.dense_transition_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the dense transition matrix.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>None</strong></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>matrix</strong> : numpy.ndarray, shape (n_states, n_states)</p>
<blockquote class="last">
<div><p>A dense transition matrix, containing the log probability
of transitioning from each state to each other state.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.edge_count">
<code class="descname">edge_count</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.edge_count" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of edges present in the model.</p>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model to data using either Baum-Welch or Viterbi training.</p>
<p>Given a list of sequences, performs re-estimation on the model
parameters. The two supported algorithms are &#8220;baum-welch&#8221; and
&#8220;viterbi,&#8221; indicating their respective algorithm.</p>
<p>Training supports a wide variety of other options including using
edge pseudocounts and either edge or distribution inertia.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequences</strong> : array-like</p>
<blockquote>
<div><p>An array of some sort (list, numpy.ndarray, tuple..) of sequences,
where each sequence is a numpy array, which is 1 dimensional if
the HMM is a one dimensional array, or multidimensional of the HMM
supports multiple dimensions.</p>
</div></blockquote>
<p><strong>weights</strong> : array-like or None, optional</p>
<blockquote>
<div><p>An array of weights, one for each sequence to train on. If None,
all sequences are equaly weighted. Default is None.</p>
</div></blockquote>
<p><strong>stop_threshold</strong> : double, optional</p>
<blockquote>
<div><p>The threshold the improvement ratio of the models log probability
in fitting the scores. Default is 1e-9.</p>
</div></blockquote>
<p><strong>min_iterations</strong> : int, optional</p>
<blockquote>
<div><p>The minimum number of iterations to run Baum-Welch training for.
Default is 0.</p>
</div></blockquote>
<p><strong>max_iterations</strong> : int, optional</p>
<blockquote>
<div><p>The maximum number of iterations to run Baum-Welch training for.
Default is 1e8.</p>
</div></blockquote>
<p><strong>algorithm</strong> : &#8216;baum-welch&#8217;, &#8216;viterbi&#8217;</p>
<blockquote>
<div><p>The training algorithm to use. Baum-Welch uses the forward-backward
algorithm to train using a version of structured EM. Viterbi
iteratively runs the sequences through the Viterbi algorithm and
then uses hard assignments of observations to states using that.
Default is &#8216;baum-welch&#8217;.</p>
</div></blockquote>
<p><strong>verbose</strong> : bool, optional</p>
<blockquote>
<div><p>Whether to print the improvement in the model fitting at each
iteration. Default is True.</p>
</div></blockquote>
<p><strong>transition_pseudocount</strong> : int, optional</p>
<blockquote>
<div><p>A pseudocount to add to all transitions to add a prior to the
MLE estimate of the transition probability. Default is 0.</p>
</div></blockquote>
<p><strong>use_pseudocount</strong> : bool, optional</p>
<blockquote>
<div><p>Whether to use pseudocounts when updatiing the transition
probability parameters. Default is False.</p>
</div></blockquote>
<p><strong>inertia</strong> : double or None, optional, range [0, 1]</p>
<blockquote>
<div><p>If double, will set both edge_inertia and distribution_inertia to
be that value. If None, will not override those values. Default is
None.</p>
</div></blockquote>
<p><strong>edge_inertia</strong> : bool, optional, range [0, 1]</p>
<blockquote>
<div><p>Whether to use inertia when updating the transition probability
parameters. Default is 0.0.</p>
</div></blockquote>
<p><strong>distribution_inertia</strong> : double, optional, range [0, 1]</p>
<blockquote>
<div><p>Whether to use inertia when updating the distribution parameters.
Default is 0.0.</p>
</div></blockquote>
<p><strong>n_jobs</strong> : int, optional</p>
<blockquote>
<div><p>The number of threads to use when performing training. This
leads to exact updates. Default is 1.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>improvement</strong> : double</p>
<blockquote class="last">
<div><p>The total improvement in fitting the model to the data</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the forward algorithm on the sequence.</p>
<p>Calculate the probability of each observation being aligned to each
state by going forward through a sequence. Returns the full forward
matrix. Each index i, j corresponds to the sum-of-all-paths log
probability of starting at the beginning of the sequence, and aligning
observations to hidden states in such a manner that observation i was
aligned to hidden state j. Uses row normalization to dynamically scale
each row to prevent underflow errors.</p>
<p>If the sequence is impossible, will return a matrix of nans.</p>
<dl class="docutils">
<dt>See also:</dt>
<dd><ul class="first last simple">
<li>Silent state handling taken from p. 71 of &#8220;Biological</li>
</ul>
</dd>
</dl>
<p>Sequence Analysis&#8221; by Durbin et al., and works for anything which
does not have loops of silent states.</p>
<blockquote>
<div><ul class="simple">
<li>Row normalization technique explained by</li>
</ul>
</div></blockquote>
<p><a class="reference external" href="http://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf">http://www.cs.sjsu.edu/~stamp/RUA/HMM.pdf</a> on p. 14.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>An array (or list) of observations.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>matrix</strong> : array-like, shape (len(sequence), n_states)</p>
<blockquote class="last">
<div><p>The probability of aligning the sequences to states in a forward
fashion.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.forward_backward">
<code class="descname">forward_backward</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.forward_backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the forward-backward algorithm on the sequence.</p>
<p>This algorithm returns an emission matrix and a transition matrix. The
emission matrix returns the normalized probability that each each state
generated that emission given both the symbol and the entire sequence.
The transition matrix returns the expected number of times that a
transition is used.</p>
<p>If the sequence is impossible, will return (None, None)</p>
<dl class="docutils">
<dt>See also:</dt>
<dd><ul class="first simple">
<li>Forward and backward algorithm implementations. A comprehensive</li>
</ul>
<p class="last">description of the forward, backward, and forward-background
algorithm is here:
<a class="reference external" href="http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm">http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm</a></p>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>An array (or list) of observations.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>emissions</strong> : array-like, shape (len(sequence), n_nonsilent_states)</p>
<blockquote>
<div><p>The normalized probabilities of each state generating each emission.</p>
</div></blockquote>
<p><strong>transitions</strong> : array-like, shape (n_states, n_states)</p>
<blockquote class="last">
<div><p>The expected number of transitions across each edge in the model.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.freeze">
<code class="descname">freeze</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze the distribution, preventing updates from occuring.</p>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.freeze_distributions">
<code class="descname">freeze_distributions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.freeze_distributions" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze all the distributions in model.</p>
<p>Upon training only edges will be updated. The parameters of
distributions will not be affected.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>None</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.from_json">
<code class="descname">from_json</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.from_json" title="Permalink to this definition">¶</a></dt>
<dd><p>Read in a serialized model and return the appropriate classifier.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>s</strong> : str</p>
<blockquote>
<div><p>A JSON formatted string containing the file.</p>
</div></blockquote>
<p><strong>Returns</strong></p>
<p><strong>&#8212;&#8212;-</strong></p>
<p><strong>model</strong> : object</p>
<blockquote class="last">
<div><p>A properly initialized and baked model.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.from_matrix">
<code class="descname">from_matrix</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.from_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a model from a more standard matrix format.</p>
<p>Take in a 2D matrix of floats of size n by n, which are the transition
probabilities to go from any state to any other state. May also take in
a list of length n representing the names of these nodes, and a model
name. Must provide the matrix, and a list of size n representing the
distribution you wish to use for that state, a list of size n indicating
the probability of starting in a state, and a list of size n indicating
the probability of ending in a state.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>transition_probabilities</strong> : array-like, shape (n_states, n_states)</p>
<blockquote>
<div><p>The probabilities of each state transitioning to each other state.</p>
</div></blockquote>
<p><strong>distributions</strong> : array-like, shape (n_states)</p>
<blockquote>
<div><p>The distributions for each state. Silent states are indicated by
using None instead of a distribution object.</p>
</div></blockquote>
<p><strong>starts</strong> : array-like, shape (n_states)</p>
<blockquote>
<div><p>The probabilities of starting in each of the states.</p>
</div></blockquote>
<p><strong>ends</strong> : array-like, shape (n_states), optional</p>
<blockquote>
<div><p>If passed in, the probabilities of ending in each of the states.
If ends is None, then assumes the model has no explicit end
state. Default is None.</p>
</div></blockquote>
<p><strong>state_names</strong> : array-like, shape (n_states), optional</p>
<blockquote>
<div><p>The name of the states. If None is passed in, default names are
generated. Default is None</p>
</div></blockquote>
<p><strong>name</strong> : str, optional</p>
<blockquote>
<div><p>The name of the model. Default is None</p>
</div></blockquote>
<p><strong>verbose</strong> : bool, optional</p>
<blockquote>
<div><p>The verbose parameter for the underlying bake method. Default is False.</p>
</div></blockquote>
<p><strong>merge</strong> : &#8216;None&#8217;, &#8216;Partial&#8217;, &#8216;All&#8217;, optional</p>
<blockquote>
<div><p>The merge parameter for the underlying bake method. Default is All</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>model</strong> : HiddenMarkovModel</p>
<blockquote class="last">
<div><p>The baked model ready to go.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>matrix = [ [ 0.4, 0.5 ], [ 0.4, 0.5 ] ]
distributions = [NormalDistribution(1, .5), NormalDistribution(5, 2)]
starts = [ 1., 0. ]
ends = [ .1., .1 ]
state_names= [ &#8220;A&#8221;, &#8220;B&#8221; ]</p>
<dl class="docutils">
<dt>model = Model.from_matrix( matrix, distributions, starts, ends,</dt>
<dd>state_names, name=&#8221;test_model&#8221; )</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.from_summaries">
<code class="descname">from_summaries</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.from_summaries" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model to the stored summary statistics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>inertia</strong> : double or None, optional</p>
<blockquote>
<div><p>The inertia to use for both edges and distributions without
needing to set both of them. If None, use the values passed
in to those variables. Default is None.</p>
</div></blockquote>
<p><strong>transition_pseudocount</strong> : int, optional</p>
<blockquote>
<div><p>A pseudocount to add to all transitions to add a prior to the
MLE estimate of the transition probability. Default is 0.</p>
</div></blockquote>
<p><strong>use_pseudocount</strong> : bool, optional</p>
<blockquote>
<div><p>Whether to use pseudocounts when updatiing the transition
probability parameters. Default is False.</p>
</div></blockquote>
<p><strong>edge_inertia</strong> : bool, optional, range [0, 1]</p>
<blockquote>
<div><p>Whether to use inertia when updating the transition probability
parameters. Default is 0.0.</p>
</div></blockquote>
<p><strong>distribution_inertia</strong> : double, optional, range [0, 1]</p>
<blockquote>
<div><p>Whether to use inertia when updating the distribution parameters.
Default is 0.0.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.log_probability">
<code class="descname">log_probability</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.log_probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the log probability of a single sequence.</p>
<p>If a path is provided, calculate the log probability of that sequence
given the path.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>Return the array of observations in a single sequence of data</p>
</div></blockquote>
<p><strong>check_input</strong> : bool, optional</p>
<blockquote>
<div><p>Check to make sure that all emissions fall under the support of
the emission distributions. Default is True.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>logp</strong> : double</p>
<blockquote class="last">
<div><p>The log probability of the sequence</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.maximum_a_posteriori">
<code class="descname">maximum_a_posteriori</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.maximum_a_posteriori" title="Permalink to this definition">¶</a></dt>
<dd><p>Run posterior decoding on the sequence.</p>
<p>MAP decoding is an alternative to viterbi decoding, which returns the
most likely state for each observation, based on the forward-backward
algorithm. This is also called posterior decoding. This method is
described on p. 14 of <a class="reference external" href="http://ai.stanford.edu/~serafim/CS262_2007/">http://ai.stanford.edu/~serafim/CS262_2007/</a>
notes/lecture5.pdf</p>
<p>WARNING: This may produce impossible sequences.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>An array (or list) of observations.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>logp</strong> : double</p>
<blockquote>
<div><p>The log probability of the sequence under the Viterbi path</p>
</div></blockquote>
<p><strong>path</strong> : list of tuples</p>
<blockquote class="last">
<div><p>Tuples of (state index, state object) of the states along the
posterior path.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.node_count">
<code class="descname">node_count</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.node_count" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of nodes/states in the model</p>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.plot">
<code class="descname">plot</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw this model&#8217;s graph using NetworkX and matplotlib.</p>
<p>Note that this relies on networkx&#8217;s built-in graphing capabilities (and
not Graphviz) and thus can&#8217;t draw self-loops.</p>
<p>See networkx.draw_networkx() for the keywords you can pass in.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>precision</strong> : int, optional</p>
<blockquote>
<div><p>The precision with which to round edge probabilities.
Default is 4.</p>
</div></blockquote>
<p><strong>**kwargs</strong> : any</p>
<blockquote>
<div><p>The arguments to pass into networkx.draw_networkx()</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the most likely state for each observation.</p>
<p>This can be either the Viterbi algorithm or maximum a posteriori. It
returns the probability of the sequence under that state sequence and
the actual state sequence.</p>
<p>This is a sklearn wrapper for the Viterbi and maximum_a_posteriori methods.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>An array (or list) of observations.</p>
</div></blockquote>
<p><strong>algorithm</strong> : &#8220;map&#8221;, &#8220;viterbi&#8221;</p>
<blockquote>
<div><p>The algorithm with which to decode the sequence</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>logp</strong> : double</p>
<blockquote>
<div><p>The log probability of the sequence under the Viterbi path</p>
</div></blockquote>
<p><strong>path</strong> : list of tuples</p>
<blockquote class="last">
<div><p>Tuples of (state index, state object) of the states along the
Viterbi path.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the state log probabilities for each observation in the sequence.</p>
<p>Run the forward-backward algorithm on the sequence and return the emission
matrix. This is the log normalized probability that each each state
generated that emission given both the symbol and the entire sequence.</p>
<p>This is a sklearn wrapper for the forward backward algorithm.</p>
<dl class="docutils">
<dt>See also:</dt>
<dd><ul class="first simple">
<li>Forward and backward algorithm implementations. A comprehensive</li>
</ul>
<p class="last">description of the forward, backward, and forward-background
algorithm is here:
<a class="reference external" href="http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm">http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm</a></p>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>An array (or list) of observations.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>emissions</strong> : array-like, shape (len(sequence), n_nonsilent_states)</p>
<blockquote class="last">
<div><p>The log normalized probabilities of each state generating each emission.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the state probabilities for each observation in the sequence.</p>
<p>Run the forward-backward algorithm on the sequence and return the emission
matrix. This is the normalized probability that each each state
generated that emission given both the symbol and the entire sequence.</p>
<p>This is a sklearn wrapper for the forward backward algorithm.</p>
<dl class="docutils">
<dt>See also:</dt>
<dd><ul class="first simple">
<li>Forward and backward algorithm implementations. A comprehensive</li>
</ul>
<p class="last">description of the forward, backward, and forward-background
algorithm is here:
<a class="reference external" href="http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm">http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm</a></p>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>An array (or list) of observations.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>emissions</strong> : array-like, shape (len(sequence), n_nonsilent_states)</p>
<blockquote class="last">
<div><p>The normalized probabilities of each state generating each emission.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.probability">
<code class="descname">probability</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the probability of the given symbol under this distribution.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>symbol</strong> : object</p>
<blockquote>
<div><p>The symbol to calculate the probability of</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>probability</strong> : double</p>
<blockquote class="last">
<div><p>The probability of that point under the distribution.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a sequence from the model.</p>
<p>Returns the sequence generated, as a list of emitted items. The
model must have been baked first in order to run this method.</p>
<p>If a length is specified and the HMM is infinite (no edges to the
end state), then that number of samples will be randomly generated.
If the length is specified and the HMM is finite, the method will
attempt to generate a prefix of that length. Currently it will force
itself to not take an end transition unless that is the only path,
making it not a true random sample on a finite model.</p>
<p>WARNING: If the HMM has no explicit end state, must specify a length
to use.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>length</strong> : int, optional</p>
<blockquote>
<div><p>Generate a sequence with a maximal length of this size. Used if
you have no explicit end state. Default is 0.</p>
</div></blockquote>
<p><strong>path</strong> : bool, optional</p>
<blockquote>
<div><p>Return the path of hidden states in addition to the emissions. If
true will return a tuple of (sample, path). Default is False.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>sample</strong> : list or tuple</p>
<blockquote class="last">
<div><p>If path is true, return a tuple of (sample, path), otherwise return
just the samples.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.state_count">
<code class="descname">state_count</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.state_count" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of states present in the model.</p>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.summarize">
<code class="descname">summarize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.summarize" title="Permalink to this definition">¶</a></dt>
<dd><p>Summarize data into stored sufficient statistics for out-of-core
training. Only implemented for Baum-Welch training since Viterbi
is less memory intensive.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequences</strong> : array-like</p>
<blockquote>
<div><p>An array of some sort (list, numpy.ndarray, tuple..) of sequences,
where each sequence is a numpy array, which is 1 dimensional if
the HMM is a one dimensional array, or multidimensional of the HMM
supports multiple dimensions.</p>
</div></blockquote>
<p><strong>weights</strong> : array-like or None, optional</p>
<blockquote>
<div><p>An array of weights, one for each sequence to train on. If None,
all sequences are equaly weighted. Default is None.</p>
</div></blockquote>
<p><strong>n_jobs</strong> : int, optional</p>
<blockquote>
<div><p>The number of threads to use when performing training. This
leads to exact updates. Default is 1.</p>
</div></blockquote>
<p><strong>algorithm</strong> : &#8216;baum-welch&#8217; or &#8216;viterbi&#8217;, optional</p>
<blockquote>
<div><p>The algorithm to use to collect the statistics, either Baum-Welch
or Viterbi training. Defaults to Baum-Welch.</p>
</div></blockquote>
<p><strong>parallel</strong> : joblib.Parallel or None, optional</p>
<blockquote>
<div><p>The joblib threadpool. Passed between iterations of Baum-Welch so
that a new threadpool doesn&#8217;t have to be created each iteration.
Default is None.</p>
</div></blockquote>
<p><strong>check_input</strong> : bool, optional</p>
<blockquote>
<div><p>Check the input. This casts the input sequences as numpy arrays,
and converts non-numeric inputs into numeric inputs for faster
processing later. Default is True.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>logp</strong> : double</p>
<blockquote class="last">
<div><p>The log probability of the sequences.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.thaw">
<code class="descname">thaw</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.thaw" title="Permalink to this definition">¶</a></dt>
<dd><p>Thaw the distribution, re-allowing updates to occur.</p>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.thaw_distributions">
<code class="descname">thaw_distributions</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.thaw_distributions" title="Permalink to this definition">¶</a></dt>
<dd><p>Thaw all distributions in the model.</p>
<p>Upon training distributions will be updated again.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>None</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.to_json">
<code class="descname">to_json</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.to_json" title="Permalink to this definition">¶</a></dt>
<dd><p>Serialize the model to a JSON.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>separators</strong> : tuple, optional</p>
<blockquote>
<div><p>The two separaters to pass to the json.dumps function for formatting.</p>
</div></blockquote>
<p><strong>indent</strong> : int, optional</p>
<blockquote>
<div><p>The indentation to use at each level. Passed to json.dumps for
formatting.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>json</strong> : str</p>
<blockquote class="last">
<div><p>A properly formatted JSON object.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pomegranate.hmm.HiddenMarkovModel.viterbi">
<code class="descname">viterbi</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.HiddenMarkovModel.viterbi" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the Viteri algorithm on the sequence.</p>
<p>Run the Viterbi algorithm on the sequence given the model. This finds
the ML path of hidden states given the sequence. Returns a tuple of the
log probability of the ML path, or (-inf, None) if the sequence is
impossible under the model. If a path is returned, it is a list of
tuples of the form (sequence index, state object).</p>
<p>This is fundamentally the same as the forward algorithm using max
instead of sum, except the traceback is more complicated, because
silent states in the current step can trace back to other silent states
in the current step as well as states in the previous step.</p>
<dl class="docutils">
<dt>See also:</dt>
<dd><ul class="first simple">
<li>Viterbi implementation described well in the wikipedia article</li>
</ul>
<p class="last"><a class="reference external" href="http://en.wikipedia.org/wiki/Viterbi_algorithm">http://en.wikipedia.org/wiki/Viterbi_algorithm</a></p>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>sequence</strong> : array-like</p>
<blockquote>
<div><p>An array (or list) of observations.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>logp</strong> : double</p>
<blockquote>
<div><p>The log probability of the sequence under the Viterbi path</p>
</div></blockquote>
<p><strong>path</strong> : list of tuples</p>
<blockquote class="last">
<div><p>Tuples of (state index, state object) of the states along the
Viterbi path.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="pomegranate.hmm.log">
<code class="descclassname">pomegranate.hmm.</code><code class="descname">log</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pomegranate.hmm.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the natural log of the value or -infinity if the value is 0.</p>
</dd></dl>

</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="NaiveBayes.html" class="btn btn-neutral float-right" title="Naive Bayes Classifiers" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="GeneralMixtureModel.html" class="btn btn-neutral" title="General Mixture Models" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Jacob Schreiber.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.6.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>