{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "author: Jacob Schreiber <br>\n",
    "contact: jmschreiber91@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Markov models (HMMs) are the flagship of the pomegranate package, in that most time is spent improving their implementation, and these improvements sometimes trickle down into the other algorithms. Lets delve into the features which pomegranate offers.\n",
    "\n",
    "Hidden Markov models are a form of structured prediction method which extend general mixture models to sequences of data, where position in the sequence is relevant. If each point in this sequence is completely independent of the other points, then HMMs are not the right tools and GMMs (or more complicated Bayesian networks) may be a better tool.\n",
    "\n",
    "The most common examples of HMMs come from bioinformatics and natural language processing. Since I am a bioinformatician, I will predominately use examples from bioinformatics.\n",
    "\n",
    "Lets take the simplified example of CG island detection on a sequence of DNA. DNA is made up of the four canonical nucleotides, abbreviated 'A', 'C', 'G', and 'T'. Specific organizations of these nucleotides encode enough information to build you, a human being. One simple region in the genome is called the 'CG' island, where the nucleotides 'C' and 'G' are enriched. Lets compare the predictions of a GMM with the predictions of a HMM, to both understand conceptually the differences between the two, and to see how easy it is to use pomegranate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['random', 'i0', 'log']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from pomegranate import *\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = list('CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC')\n",
    "\n",
    "d1 = DiscreteDistribution({'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25})\n",
    "d2 = DiscreteDistribution({'A': 0.10, 'C': 0.40, 'G': 0.40, 'T': 0.10})\n",
    "\n",
    "s1 = State( d1, name='background' )\n",
    "s2 = State( d2, name='CG island' )\n",
    "\n",
    "gmm = GeneralMixtureModel( [d1, d2] )\n",
    "hmm = HiddenMarkovModel()\n",
    "hmm.add_states(s1, s2)\n",
    "hmm.add_transition( hmm.start, s1, 0.5 )\n",
    "hmm.add_transition( hmm.start, s2, 0.5 )\n",
    "hmm.add_transition( s1, s1, 0.5 )\n",
    "hmm.add_transition( s1, s2, 0.5 )\n",
    "hmm.add_transition( s2, s1, 0.5 )\n",
    "hmm.add_transition( s2, s2, 0.5 )\n",
    "hmm.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "gmm pred: 110100101010010111110111101011110100001011110001111\n",
      "hmm pred: 001011010101101000001000010100001011110100001110000\n"
     ]
    }
   ],
   "source": [
    "gmm_predictions = gmm.predict( np.array(seq) )\n",
    "hmm_predictions = hmm.predict( seq )\n",
    "\n",
    "print \"sequence: {}\".format( ''.join( seq ) )\n",
    "print \"gmm pred: {}\".format( ''.join( map( str, gmm_predictions ) ) )\n",
    "print \"hmm pred: {}\".format( ''.join( map( str, hmm_predictions ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The HMM and GMM predictions may be the inverse of each other, because HMM states undergo a topological sort in order to properly handle silent states (more later), which can cause the order they were inserted into the model. \n",
    "\n",
    "Your first reaction may to say \"But Jacob, you just said that HMMs and GMMs are different. Why shold I make a HMM when making a GMM is so easy?\". \n",
    "\n",
    "My point in showing you this is that a dense HMM with equal probabilities between each state is ~equivalent~ to a GMM. However, this framework gives us great flexibility to add prior knowledge, whereas a GMM doesn't. If we look at the predictions, we see that it's bifurcating between \"background\" and \"CG island\" very quickly--in essence, calling every C or G a 'CG island'. This is not likely to be true. We know that CG islands have some As and Ts in them, and background sequence has Cs and Gs. We can change the transition probabilities to account for this, and prevent switching from occuring too rapidly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm = HiddenMarkovModel()\n",
    "hmm.add_states(s1, s2)\n",
    "hmm.add_transition( hmm.start, s1, 0.5 )\n",
    "hmm.add_transition( hmm.start, s2, 0.5 )\n",
    "hmm.add_transition( s1, s1, 0.9 )\n",
    "hmm.add_transition( s1, s2, 0.1 )\n",
    "hmm.add_transition( s2, s1, 0.1 )\n",
    "hmm.add_transition( s2, s2, 0.9 )\n",
    "hmm.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "gmm pred: 110100101010010111110111101011110100001011110001111\n",
      "hmm pred: 111111111111111000000000000000011111111111111110000\n",
      "\n",
      "hmm state 0: CG island\n",
      "hmm state 1: background\n"
     ]
    }
   ],
   "source": [
    "hmm_predictions = hmm.predict( seq )\n",
    "\n",
    "print \"sequence: {}\".format( ''.join( seq ) )\n",
    "print \"gmm pred: {}\".format( ''.join( map( str, gmm_predictions ) ) )\n",
    "print \"hmm pred: {}\".format( ''.join( map( str, hmm_predictions ) ) )\n",
    "print\n",
    "print \"hmm state 0: {}\".format( hmm.states[0].name )\n",
    "print \"hmm state 1: {}\".format( hmm.states[1].name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems far more reasonable. There is a single CG island surrounded by background sequence, and something at the end. If we knew that CG islands cannot occur at the end of sequences, we need only modify the underlying structure of the HMM in order to say that the sequence must end from the background state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm = HiddenMarkovModel()\n",
    "hmm.add_states(s1, s2)\n",
    "hmm.add_transition( hmm.start, s1, 0.5 )\n",
    "hmm.add_transition( hmm.start, s2, 0.5 )\n",
    "hmm.add_transition( s1, s1, 0.89 )\n",
    "hmm.add_transition( s1, s2, 0.10 )\n",
    "hmm.add_transition( s1, hmm.end, 0.01 )\n",
    "hmm.add_transition( s2, s1, 0.1 )\n",
    "hmm.add_transition( s2, s2, 0.9 )\n",
    "hmm.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "gmm pred: 110100101010010111110111101011110100001011110001111\n",
      "hmm pred: 111111111111111000000000000000011111111111111111111\n",
      "\n",
      "hmm state 0: CG island\n",
      "hmm state 1: background\n"
     ]
    }
   ],
   "source": [
    "hmm_predictions = hmm.predict( seq )\n",
    "\n",
    "print \"sequence: {}\".format( ''.join( seq ) )\n",
    "print \"gmm pred: {}\".format( ''.join( map( str, gmm_predictions ) ) )\n",
    "print \"hmm pred: {}\".format( ''.join( map( str, hmm_predictions ) ) )\n",
    "print\n",
    "print \"hmm state 0: {}\".format( hmm.states[0].name )\n",
    "print \"hmm state 1: {}\".format( hmm.states[1].name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we managed to get rid of that pesky end (again, the numbers may have flipped, look at the indices). Modifying transition probabilities and using non-dense graphical structures are two major ways in which HMMs account for data in a sequence not being independent and identically distributed (i.i.d.). In fact, in most applications, the graphical structure of a HMM is very sparse. \n",
    "\n",
    "If we want a more probabilistic view of what's going on, we can get the probability of each symbol in the sequence being in each of the states in the model easily. This is useful to get a soft estimate of classification, which allows us to include confidence as well as prediction. Values close to 50-50 get masked when you make hard classifications, but this uncertainty can be passed to future applications if you use soft assignments. Each row in the matrix is one symbol in the sequence, and the columns correspond to the two states identified above (CG island or background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4827054   0.5172946 ]\n",
      " [ 0.42204064  0.57795936]\n",
      " [ 0.28598775  0.71401225]\n",
      " [ 0.25756456  0.74243544]\n",
      " [ 0.16040038  0.83959962]\n",
      " [ 0.13871983  0.86128017]\n",
      " [ 0.17217854  0.82782146]\n",
      " [ 0.14750165  0.85249835]\n",
      " [ 0.18021186  0.81978814]\n",
      " [ 0.15446181  0.84553819]\n",
      " [ 0.18788044  0.81211956]\n",
      " [ 0.16252887  0.83747113]\n",
      " [ 0.19841088  0.80158912]\n",
      " [ 0.32919701  0.67080299]\n",
      " [ 0.38366073  0.61633927]\n",
      " [ 0.58044619  0.41955381]\n",
      " [ 0.69075524  0.30924476]\n",
      " [ 0.74653183  0.25346817]\n",
      " [ 0.76392808  0.23607192]\n",
      " [ 0.7479817   0.2520183 ]\n",
      " [ 0.69407484  0.30592516]\n",
      " [ 0.74761829  0.25238171]\n",
      " [ 0.76321595  0.23678405]\n",
      " [ 0.74538467  0.25461533]\n",
      " [ 0.68896078  0.31103922]\n",
      " [ 0.57760471  0.42239529]\n",
      " [ 0.58391467  0.41608533]\n",
      " [ 0.53953778  0.46046222]\n",
      " [ 0.6030831   0.3969169 ]\n",
      " [ 0.61516689  0.38483311]\n",
      " [ 0.57928847  0.42071153]\n",
      " [ 0.48505793  0.51494207]\n",
      " [ 0.30518744  0.69481256]\n",
      " [ 0.25379428  0.74620572]\n",
      " [ 0.12610747  0.87389253]\n",
      " [ 0.08105965  0.91894035]\n",
      " [ 0.07637934  0.92362066]\n",
      " [ 0.10767468  0.89232532]\n",
      " [ 0.20431225  0.79568775]\n",
      " [ 0.23273876  0.76726124]\n",
      " [ 0.35851961  0.64148039]\n",
      " [ 0.40985726  0.59014274]\n",
      " [ 0.40161837  0.59838163]\n",
      " [ 0.33141706  0.66858294]\n",
      " [ 0.17892403  0.82107597]\n",
      " [ 0.12850549  0.87149451]\n",
      " [ 0.13285026  0.86714974]\n",
      " [ 0.19603531  0.80396469]\n",
      " [ 0.19760431  0.80239569]\n",
      " [ 0.13801161  0.86198839]\n",
      " [ 0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print hmm.predict_proba( seq )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a corresponding `hmm.predict_log_proba` method present if you want to get the log values. These are the emission probability values calculated by the forward backward algorithm, and can also be retrieved by calling `hmm.forward_backward( seq )`, which returns both the emission and the transition probability tables.\n",
    "\n",
    "Lets take a look at these tables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15.78100555   2.89559314   0.           0.        ]\n",
      " [  2.41288774  28.91051356   1.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.4827054    0.5172946    0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "trans, ems = hmm.forward_backward( seq )\n",
    "print trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the transition table, which has the soft count of the number of transitions across an edge in the model given a single sequence. It is a square matrix of size equal to the number of states (including start and end state), with number of transitions from (row_id) to (column_id). This is exemplified by the 1.0 in the first row, indicating that there is one transition from background state to the end state, as that's the only way to reach the end state. However, the third (or fourth, depending on ordering) row is the transitions from the start state, and it only slightly favors the background state. These counts are not normalized to the length of the input sequence, but can easily be done so by dividing by row sums, column sums, or entire table sums, depending on your application.\n",
    "\n",
    "A possible reason not to normalize is to run several sequences through and add up their tables, because normalizing in the end and extracting some domain knowledge. It is extremely useful in practice. For example, we can see that there is an expectation of 2.8956 transitions from CG island to background, and 2.4 from background to CG island. This could be used to infer that there are ~2-3 edges, which makes sense if you consider that the start and end of the sequence seem like they might be part of the CG island states except for the strict transition probabilities used (look at the first few rows of the emission table above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been using the forward backward algorithm and maximum a posteriori for decoding thus far, however maximum a posteriori decoding has the side effect that it is possible that it predicts impossible sequences in some edge cases. An alternative is Viterbi decoding, which at each step takes the most likely path, instead of sum of all paths, to produce hard assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: CGACTACTGACTACTCGCCGACGCGACTGCCGTCTATACTGCGCATACGGC\n",
      "gmm pred: 110100101010010111110111101011110100001011110001111\n",
      "hmm pred: 111111111111111111111111111111111111111111111111111\n",
      "\n",
      "hmm state 0: CG island\n",
      "hmm state 1: background\n"
     ]
    }
   ],
   "source": [
    "hmm_predictions = hmm.predict( seq, algorithm='viterbi' )[1:-1]\n",
    "\n",
    "print \"sequence: {}\".format( ''.join( seq ) )\n",
    "print \"gmm pred: {}\".format( ''.join( map( str, gmm_predictions ) ) )\n",
    "print \"hmm pred: {}\".format( ''.join( map( str, hmm_predictions ) ) )\n",
    "print\n",
    "print \"hmm state 0: {}\".format( hmm.states[0].name )\n",
    "print \"hmm state 1: {}\".format( hmm.states[1].name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here a case in which it does not do too well. The Viterbi path can be more conservative in its transitions due to the hard assignments it makes. In essence, if multiple possibile paths are possible at a given point, it takes the most likely path, even if the sum of all other paths is greater than the sum of that path. In problems with a lower signal to noise ratio, this can mask the signal. As a side note, we can use the following to get the maximum a posteriori and Viterbi paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.6959244372 -0.133504398007\n"
     ]
    }
   ],
   "source": [
    "v_logp, v_seq = hmm.viterbi( seq )\n",
    "m_logp, m_seq = hmm.maximum_a_posteriori( seq )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence predicted is a tuple of (state id, state object) for every state in the predicted path. The predict method simply takes the state ids from this path and returns those as an array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets move on to a more complicated structure, that of a profile HMM. A profile HMM is used to align a sequence to a reference 'profile', where the reference profile can either be a single sequence, or an alignment of many sequences (such as a reference genome). In essence, this profile has a 'match' state for every position in the reference profile, and 'insert' state, and a 'delete' state. The insert state allows the external sequence to have an insertion into the sequence without throwing off the entire alignment, such as the following:\n",
    "\n",
    "`ACCG : Sequence` <br>\n",
    "`|| |` <br>\n",
    "`AC-G : Reference`\n",
    "\n",
    "or a deletion, which is the opposite:\n",
    "\n",
    "`A-G : Sequence` <br>\n",
    "`| |` <br>\n",
    "`ACG : Reference`\n",
    "\n",
    "The bars in the middle refer to a perfect match, whereas the lack of a bar means either a deletion/insertion, or a mismatch. A mismatch is where two positions are aligned together, but do not match. This models the biological phenomena of mutation, where one nucleotide can convert to another over time. It is usually more likely in biological sequences that this type of mutation occurs than that the nucleotide was deleted from the sequence (shifting all nucleotides over by one) and then another was inserted at the exact location (moving all nucleotides over again). Since we are using a probabilistic model, we get to define these probabilities through the use of distributions! If we want to model mismatches, we can just set our 'match' state to have an appropriate distribution with non-zero probabilities over mismatches. \n",
    "\n",
    "Lets now create a three nucleotide profile HMM, which models the sequence 'ACT'. We will fuzz this a little bit in the match states, pretending to have some prior information about what mutations occur at each position. If you don't have any information, setting a uniform, small, value over the other values is usually okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = HiddenMarkovModel( \"Global Alignment\")\n",
    "\n",
    "# Define the distribution for insertions\n",
    "i_d = DiscreteDistribution( { 'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25 } )\n",
    "\n",
    "# Create the insert states\n",
    "i0 = State( i_d, name=\"I0\" )\n",
    "i1 = State( i_d, name=\"I1\" )\n",
    "i2 = State( i_d, name=\"I2\" )\n",
    "i3 = State( i_d, name=\"I3\" )\n",
    "\n",
    "# Create the match states\n",
    "m1 = State( DiscreteDistribution({ \"A\": 0.95, 'C': 0.01, 'G': 0.01, 'T': 0.02 }) , name=\"M1\" )\n",
    "m2 = State( DiscreteDistribution({ \"A\": 0.003, 'C': 0.99, 'G': 0.003, 'T': 0.004 }) , name=\"M2\" )\n",
    "m3 = State( DiscreteDistribution({ \"A\": 0.01, 'C': 0.01, 'G': 0.01, 'T': 0.97 }) , name=\"M3\" )\n",
    "\n",
    "# Create the delete states\n",
    "d1 = State( None, name=\"D1\" )\n",
    "d2 = State( None, name=\"D2\" )\n",
    "d3 = State( None, name=\"D3\" )\n",
    "\n",
    "# Add all the states to the model\n",
    "model.add_states( [i0, i1, i2, i3, m1, m2, m3, d1, d2, d3 ] )\n",
    "\n",
    "# Create transitions from match states\n",
    "model.add_transition( model.start, m1, 0.9 )\n",
    "model.add_transition( model.start, i0, 0.1 )\n",
    "model.add_transition( m1, m2, 0.9 )\n",
    "model.add_transition( m1, i1, 0.05 )\n",
    "model.add_transition( m1, d2, 0.05 )\n",
    "model.add_transition( m2, m3, 0.9 )\n",
    "model.add_transition( m2, i2, 0.05 )\n",
    "model.add_transition( m2, d3, 0.05 )\n",
    "model.add_transition( m3, model.end, 0.9 )\n",
    "model.add_transition( m3, i3, 0.1 )\n",
    "\n",
    "# Create transitions from insert states\n",
    "model.add_transition( i0, i0, 0.70 )\n",
    "model.add_transition( i0, d1, 0.15 )\n",
    "model.add_transition( i0, m1, 0.15 )\n",
    "\n",
    "model.add_transition( i1, i1, 0.70 )\n",
    "model.add_transition( i1, d2, 0.15 )\n",
    "model.add_transition( i1, m2, 0.15 )\n",
    "\n",
    "model.add_transition( i2, i2, 0.70 )\n",
    "model.add_transition( i2, d3, 0.15 )\n",
    "model.add_transition( i2, m3, 0.15 )\n",
    "\n",
    "model.add_transition( i3, i3, 0.85 )\n",
    "model.add_transition( i3, model.end, 0.15 )\n",
    "\n",
    "# Create transitions from delete states\n",
    "model.add_transition( d1, d2, 0.15 )\n",
    "model.add_transition( d1, i1, 0.15 )\n",
    "model.add_transition( d1, m2, 0.70 ) \n",
    "\n",
    "model.add_transition( d2, d3, 0.15 )\n",
    "model.add_transition( d2, i2, 0.15 )\n",
    "model.add_transition( d2, m3, 0.70 )\n",
    "\n",
    "model.add_transition( d3, i3, 0.30 )\n",
    "model.add_transition( d3, model.end, 0.70 )\n",
    "\n",
    "# Call bake to finalize the structure of the model.\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to align some sequences to it and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: 'ACT'  -- Log Probability: -0.513244900357 -- Path: M1 M2 M3\n",
      "Sequence: 'GGC'  -- Log Probability: -11.0481012413 -- Path: I0 I0 D1 M2 D3\n",
      "Sequence: 'GAT'  -- Log Probability: -9.12551967402 -- Path: I0 M1 D2 M3\n",
      "Sequence: 'ACC'  -- Log Probability: -5.08795587886 -- Path: M1 M2 M3\n"
     ]
    }
   ],
   "source": [
    "for sequence in map( list, ('ACT', 'GGC', 'GAT', 'ACC') ):\n",
    "    logp, path = model.viterbi( sequence )\n",
    "    print \"Sequence: '{}'  -- Log Probability: {} -- Path: {}\".format(\n",
    "        ''.join( sequence ), logp, \" \".join( state.name for idx, state in path[1:-1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and last sequence are entirely matches, meaning that it thinks the most likely alignment between the profile ACT and ACT is A-A, C-C, and T-T, which makes sense, and the most likely alignment between ACT and ACC is A-A, C-C, and T-C, which includes a mismatch. Essentially, it's more likely that there's a T-C mismatch at the end then that there was a deletion of a T at the end of the sequence, and a separate insertion of a C.\n",
    "\n",
    "The two middle sequences don't match very well, as expected! G's are not very likely in this profile at all. It predicts that the two G's are inserts, and that the C matches the C in the profile, before hitting the delete state because it can't emit a T. The third sequence thinks that the G is an insert, as expected, and then aligns the A and T in the sequence to the A and T in the master sequence, missing the middle C in the profile.\n",
    "\n",
    "By using deletes, we can handle other sequences which are shorter than three characters. Lets look at some more sequences of different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: 'A'  -- Log Probability: -5.40618101242 -- Path: M1 D2 D3\n",
      "Sequence: 'GA'  -- Log Probability: -10.8868199358 -- Path: I0 M1 D2 D3\n",
      "Sequence: 'AC'  -- Log Probability: -3.62447187905 -- Path: M1 M2 D3\n",
      "Sequence: 'AT'  -- Log Probability: -3.64488075068 -- Path: M1 D2 M3\n",
      "Sequence: 'ATCC'  -- Log Probability: -10.6743329646 -- Path: M1 D2 M3 I3 I3\n",
      "Sequence: 'ACGTG'  -- Log Probability: -10.3938248352 -- Path: M1 M2 I2 I2 I2 D3\n",
      "Sequence: 'ATTT'  -- Log Probability: -8.67126440175 -- Path: M1 I1 I1 D2 M3\n",
      "Sequence: 'TACCCTC'  -- Log Probability: -16.9034517961 -- Path: I0 I0 I0 I0 D1 M2 M3 I3\n",
      "Sequence: 'TGTCAACACT'  -- Log Probability: -16.4516996541 -- Path: I0 I0 I0 I0 I0 I0 I0 M1 M2 M3\n"
     ]
    }
   ],
   "source": [
    "for sequence in map( list, ('A', 'GA', 'AC', 'AT', 'ATCC', 'ACGTG', 'ATTT', 'TACCCTC', 'TGTCAACACT') ):\n",
    "    logp, path = model.viterbi( sequence )\n",
    "    print \"Sequence: '{}'  -- Log Probability: {} -- Path: {}\".format(\n",
    "        ''.join( sequence ), logp, \" \".join( state.name for idx, state in path[1:-1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, more of the same expected. You'll notice most of the use of insertion states are at I0, because most of the insertions are at the beginning of the sequence. It's more probable to simply stay in I0 at the beginning instead of go from I0 to D1 to I1, or going to another insert state along there. You'll see other insert states used when insertions occur in other places in the sequence, like 'ATTT' and 'ACGTG'.\n",
    "Now that we have the path, we need to convert it into an alignment, which is significantly more informative to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: A, Log Probability: -5.40618101242\n",
      "ACT\n",
      "A--\n",
      "\n",
      "Sequence: GA, Log Probability: -10.8868199358\n",
      "-ACT\n",
      "GA--\n",
      "\n",
      "Sequence: AC, Log Probability: -3.62447187905\n",
      "ACT\n",
      "AC-\n",
      "\n",
      "Sequence: AT, Log Probability: -3.64488075068\n",
      "ACT\n",
      "A-T\n",
      "\n",
      "Sequence: ATCC, Log Probability: -10.6743329646\n",
      "ACT--\n",
      "A-TCC\n",
      "\n",
      "Sequence: ACGTG, Log Probability: -10.3938248352\n",
      "AC---T\n",
      "ACGTG-\n",
      "\n",
      "Sequence: ATTT, Log Probability: -8.67126440175\n",
      "A--CT\n",
      "ATT-T\n",
      "\n",
      "Sequence: TACCCTC, Log Probability: -16.9034517961\n",
      "----ACT-\n",
      "TACC-CTC\n",
      "\n",
      "Sequence: TGTCAACACT, Log Probability: -16.4516996541\n",
      "-------ACT\n",
      "TGTCAACACT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def path_to_alignment( x, y, path ):\n",
    "    \"\"\"\n",
    "    This function will take in two sequences, and the ML path which is their alignment,\n",
    "    and insert dashes appropriately to make them appear aligned. This consists only of\n",
    "    adding a dash to the model sequence for every insert in the path appropriately, and\n",
    "    a dash in the observed sequence for every delete in the path appropriately.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, (index, state) in enumerate( path[1:-1] ):\n",
    "        name = state.name\n",
    "        \n",
    "        if name.startswith( 'D' ):\n",
    "            y = y[:i] + '-' + y[i:]\n",
    "        elif name.startswith( 'I' ):\n",
    "            x = x[:i] + '-' + x[i:]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "for sequence in map( list, ('A', 'GA', 'AC', 'AT', 'ATCC', 'ACGTG', 'ATTT', 'TACCCTC', 'TGTCAACACT') ):\n",
    "    logp, path = model.viterbi( sequence )\n",
    "    x, y = path_to_alignment( 'ACT', ''.join(sequence), path )\n",
    "    \n",
    "    print \"Sequence: {}, Log Probability: {}\".format( ''.join(sequence), logp )\n",
    "    print \"{}\\n{}\".format( x, y )\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to getting this alignment, we can do some interesting things with this model! Lets score every sequence of length 5 of less and see what the distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFKCAYAAABYaPhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11ae854950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "sequences = reduce( lambda x, y: x+y, [[ seq for seq in it.product( 'ACGT', repeat=i ) ] for i in xrange( 1,6 )] )\n",
    "scores = map( model.log_probability, sequences )\n",
    "\n",
    "plt.figure( figsize=(10,5) )\n",
    "sns.kdeplot( numpy.array( scores ), shade=True )\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel('Log Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be five local maxima. We could go more in depth in this analysis (and I do, elsewhere), but lets return to functionally using HMMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
