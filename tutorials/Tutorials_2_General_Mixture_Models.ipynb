{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "author: Jacob Schreiber <br>\n",
    "contact: jmschreiber91@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is frequently the case that the data you have is not explained by a single underlying distribution. If we want to try to recover the underlying distributions, we need to have a model which has multiple components. An example is the following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['random', 'cov', 'log']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from pomegranate import *\n",
    "%pylab inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   4.,    7.,    9.,   17.,   17.,   27.,   30.,   29.,   23.,\n",
       "          24.,   22.,   17.,   15.,   39.,  100.,  140.,  122.,   73.,\n",
       "          29.,    6.]),\n",
       " array([ -5.56573751,  -4.71804098,  -3.87034445,  -3.02264792,\n",
       "         -2.17495139,  -1.32725486,  -0.47955833,   0.36813819,\n",
       "          1.21583472,   2.06353125,   2.91122778,   3.75892431,\n",
       "          4.60662084,   5.45431737,   6.3020139 ,   7.14971043,\n",
       "          7.99740696,   8.84510349,   9.69280002,  10.54049655,  11.38819308]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqUGGuyQ16P8BMNj675GZAhQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f764e466190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.concatenate( (np.random.randn(250) * 2.75 + 1.25, np.random.randn(500) * 1.2 + 7.85) )\n",
    "np.random.shuffle(data)\n",
    "plt.hist( data, edgecolor='c', color='c', bins=20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create our initial estimate of what this distribution is a General Mixture Model. This is a model which is comprised of multiple distributions, and weights on those distributions representing the prior probability of a point falling under that distribution given no knowledge of the point itself (defaults to equal). We can have univariate mixture models by using univariate distributions, or multivariate distributions by using multivariate distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = GeneralMixtureModel( [NormalDistribution(2.5, 1), NormalDistribution(8, 1)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict the class labels of each point under this mixture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1]\n",
      "515 1 labels, 235 0 labels\n"
     ]
    }
   ],
   "source": [
    "labels = d.predict( data )\n",
    "print labels[:5]\n",
    "print \"{} 1 labels, {} 0 labels\".format( labels.sum(), labels.shape[0] - labels.sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fairly close to the number of underlying points from each distribution, off by 17 in each label. We still don't know if the labels are accurate, just the number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  9.,  14.,  17.,  20.,  47.,  33.,  49.,  55.,  45.,  42.,  47.,\n",
       "         39.,  34.,  21.,  14.,  13.,   9.,   4.,   0.,   3.]),\n",
       " array([  5.26562359,   5.57175207,   5.87788054,   6.18400902,\n",
       "          6.49013749,   6.79626596,   7.10239444,   7.40852291,\n",
       "          7.71465139,   8.02077986,   8.32690833,   8.63303681,\n",
       "          8.93916528,   9.24529376,   9.55142223,   9.85755071,\n",
       "         10.16367918,  10.46980765,  10.77593613,  11.0820646 ,  11.38819308]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqXH/D8WzmEFKzBPoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f764ec65f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( data[ labels == 0 ], edgecolor='r', color='r', bins=20 )\n",
    "plt.hist( data[ labels == 1 ], edgecolor='c', color='c', bins=20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is slightly more difficult to update the underlying components of the model because we don't have labels indicating which point came from which distribution. We could try to use the labels inferred from the model. It seems to cleanly split it, but what if our initial estimate was not very good? It could be difficult to get a good update if we had a bad prior. \n",
    "\n",
    "Another possibility is to predict the probability of each point under each component, to get a softer estimate of the labels. Lets take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   1.02552840e-21]\n",
      " [  2.86349996e-10   1.00000000e+00]\n",
      " [  1.71616221e-05   9.99982838e-01]\n",
      " [  1.00000000e+00   3.82215263e-14]\n",
      " [  3.00125160e-15   1.00000000e+00]]\n",
      "[ 237.56873233  512.43126767]\n"
     ]
    }
   ],
   "source": [
    "labels = d.predict_proba( data )\n",
    "print labels[:5]\n",
    "print labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly closer to the truth, with 15.2 off instead of 17, around 10% closer.\n",
    "\n",
    "This is the beginning of a common unsupervised training algorithm called <b>expectation maximization</b>. It has two steps, <b>expectation</b> and <b>maximization</b>. The <b>expectation</b> step involves what we just did--assigning weights based on the probability of each point being generated by each component. The next step, <b>maximization</b>, is maximizing the probability that the distribution generated these points but performing weighted MLE.\n",
    "\n",
    "This process must be iterated until convergence. Sometimes this requires only a single update, but for overlapping distributions (such as this one) it can sometimes take many iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement: 929.870988278\n",
      "Improvement: 0.793613085689\n",
      "Improvement: 0.0390630757033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "930.7036644389814"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.fit( data, verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same with multivariate distributions just as easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = np.arange(5)\n",
    "cov = np.eye(5)\n",
    "\n",
    "mgs = [ MultivariateGaussianDistribution( mu*i, cov ) for i in range(5) ]\n",
    "gmm = GeneralMixtureModel( mgs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = numpy.random.randn(1000, 5) * 5\n",
    "for i in range(5):\n",
    "    data[i::5] += np.arange(5)*i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how well some points fit under the mixture model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 0: logp -22.6332553344\n",
      "Point 1: logp -25.9076074443\n",
      "Point 2: logp -93.5137069248\n",
      "Point 3: logp -36.2767042387\n",
      "Point 4: logp -177.542691364\n",
      "Point 5: logp -9.84077727966\n",
      "Point 6: logp -57.4970262303\n",
      "Point 7: logp -24.8740282638\n",
      "Point 8: logp -50.279158487\n",
      "Point 9: logp -71.0055567739\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print \"Point {}: logp {}\".format( i, gmm.log_probability(data[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement: 44281.8637367\n",
      "Improvement: 25.8081974947\n",
      "Improvement: 8.91739135662\n",
      "Improvement: 4.63647758262\n",
      "Improvement: 2.94454867813\n",
      "Improvement: 2.12090878237\n",
      "Improvement: 1.64581922213\n",
      "Improvement: 1.31504953439\n",
      "Improvement: 1.0476410205\n",
      "Improvement: 0.821552703599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44331.121323121726"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.fit(data, verbose=True, stop_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see how well the previous points fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 0: logp -14.5431093711\n",
      "Point 1: logp -13.7876004845\n",
      "Point 2: logp -16.3978128785\n",
      "Point 3: logp -14.4055101426\n",
      "Point 4: logp -19.6070018916\n",
      "Point 5: logp -13.8939861845\n",
      "Point 6: logp -15.1630366218\n",
      "Point 7: logp -14.3881894407\n",
      "Point 8: logp -15.2537383027\n",
      "Point 9: logp -16.6332977265\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print \"Point {}: logp {}\".format( i, gmm.log_probability(data[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they're being fit significantly better than before! Training works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
